{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a19350",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import welly\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv1D, Conv2DTranspose, ZeroPadding1D, UpSampling1D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization, Lambda\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "wells = []\n",
    "\n",
    "# read LAS files and create Well objects for each file\n",
    "las_files = [\"1-BRSA-192-ESS_Default_final.las\", \"3-BRSA-168-ESS_Default_final.las\",\n",
    "             \"3-BRSA-240-ESS_Default_final.las\", \"4-BRSA-262-ESS_Default_final.las\", \"4-BRSA-420-ESS_Default_final.las\",\n",
    "            \"6-BRSA-497-ESS_Default_final.las\", \"6-BRSA-639-ESS_Default_final.las\",\n",
    "            \"4-BRSA-291D-ESS_Default_final.las\", \"1-BRSA-215-ESS_Default_final.las\", \"1-BRSA-196-ESS_Default_final.las\", \"1-BRSA-108A-ESS_Default_final.las\", \"1-BRSA-33-ESS_Default_final.las\"]\n",
    "\n",
    "for las_file in las_files:\n",
    "    well = welly.Well.from_las(las_file)\n",
    "    wells.append(well)\n",
    "\n",
    "#create a Project object with the list of Well objects\n",
    "project = welly.Project(wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PEF data from wells\n",
    "x_train = []\n",
    "for well_data in project:\n",
    "\n",
    "    well_df = well_data.df(keys=desired_curves, basis=depth_interval)\n",
    "    # Check for NaN's in well's PEF data\n",
    "    nan_in_df = well_df.isna().any().any()\n",
    "    print('Are there NaNs in PEF data: ', nan_in_df)\n",
    "    well_pef_data = np.array(well_df['PEF'])\n",
    "    x_train.append(well_pef_data)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebee3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add channel axis\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "\n",
    "# normalize data between -1 and 1\n",
    "min_data = min(x_train.flatten())\n",
    "max_data = max(x_train.flatten())\n",
    "data_diff = max_data - min_data\n",
    "\n",
    "norm_pad = 0.1\n",
    "norm_diff = data_diff*(1.+norm_pad*2)\n",
    "norm_min = min_data-data_diff*norm_pad\n",
    "x_train = 2*(x_train-norm_min)/norm_diff-1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_log = x_train.shape[1] # 60\n",
    "channels = 1\n",
    "latent_dim = 100\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e45c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Sequential()\n",
    "depth = 8\n",
    "ks = 5\n",
    "dropout = 0.25\n",
    "\n",
    "# In: 60 x 1, depth = 1\n",
    "# Out: 30 x 1, depth=8\n",
    "input_shape = (samples_per_log, channels)\n",
    "D.add(Conv1D(depth*1, kernel_size=ks, strides=2, input_shape=input_shape, padding='same'))\n",
    "D.add(LeakyReLU(alpha=0.2))\n",
    "D.add(Dropout(rate=dropout))\n",
    "\n",
    "# In: 30 x 1, depth=8\n",
    "# Out: 15 x 1, depth=16\n",
    "D.add(Conv1D(depth*2, kernel_size=ks, strides=2, padding='same'))\n",
    "D.add(BatchNormalization(momentum=0.8))\n",
    "D.add(LeakyReLU(alpha=0.2))\n",
    "D.add(Dropout(rate=dropout))\n",
    "\n",
    "# In: 15 x 1, depth=16\n",
    "# Out: 8 x 1, depth=32\n",
    "D.add(ZeroPadding1D(padding=(0,1)))\n",
    "D.add(Conv1D(depth*4, kernel_size=ks, strides=2, padding='same'))\n",
    "D.add(BatchNormalization(momentum=0.8))\n",
    "D.add(LeakyReLU(alpha=0.2))\n",
    "D.add(Dropout(rate=dropout))\n",
    "\n",
    "# In: 8 x 1, depth=32\n",
    "# Out: 4 x 1, depth=64\n",
    "D.add(Conv1D(depth*8, kernel_size=ks, strides=2, padding='same'))\n",
    "D.add(BatchNormalization(momentum=0.8))\n",
    "D.add(LeakyReLU(alpha=0.2))\n",
    "D.add(Dropout(rate=dropout))\n",
    "\n",
    "# Out: 1-dim probability\n",
    "D.add(Flatten())\n",
    "D.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "D.summary()\n",
    "\n",
    "img = Input(shape=input_shape)\n",
    "validity = D(img)\n",
    "\n",
    "discriminator = Model(img,validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Sequential()\n",
    "depth = 32\n",
    "ks = 5\n",
    "dropout = 0.25\n",
    "dim = 15\n",
    "\n",
    "# In: 100\n",
    "# Out: 15 x 32\n",
    "G.add(Dense(dim*depth, input_dim=latent_dim))\n",
    "G.add(LeakyReLU(alpha=0.2))\n",
    "G.add(Reshape((dim, 1, depth)))\n",
    "\n",
    "# In: 15 x 1 x 32\n",
    "# Out: 30 x 1 x 16\n",
    "G.add(Conv2DTranspose(filters=depth//2,kernel_size=(ks,1),strides=(2,1),padding='same'))\n",
    "G.add(BatchNormalization(momentum=0.8))\n",
    "G.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "# In: 30 x 1 x 16\n",
    "# Out: 60 x 1 x 8\n",
    "G.add(Conv2DTranspose(filters=depth//4,kernel_size=(ks,1),strides=(2,1), padding='same'))\n",
    "G.add(BatchNormalization(momentum=0.8))\n",
    "G.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "# In: 60 x 1 x 8\n",
    "# Out: 60 x 1\n",
    "G.add(Reshape((samples_per_log,-1)))\n",
    "G.add(Conv1D(channels, ks, strides=1, padding='same'))\n",
    "G.add(Activation('tanh'))\n",
    "G.summary()\n",
    "\n",
    "noise = Input(shape=(latent_dim,))\n",
    "img = G(noise)\n",
    "\n",
    "generator = Model(noise,img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b352a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "\n",
    "valid = discriminator(img)\n",
    "\n",
    "\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=[binary_accuracy])\n",
    "\n",
    "discriminator.trainable = True\n",
    "# define helper function plot well logs data\n",
    "def plot_16_images(images, epoch=0, xlim=[-1,1]):\n",
    "    '''\n",
    "    plot 16 logs in a 4x4 grid\n",
    "    if epoch < 0, assume they are training logs\n",
    "    otherwise, assume they're generated after training epoch # epoch\n",
    "    '''\n",
    "    fake = epoch >= 0\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        image = images[i]\n",
    "        plt.plot(image,np.arange(len(image)))\n",
    "        plt.xlim(xlim)\n",
    "        plt.gca().invert_yaxis()\n",
    "    plt.tight_layout(rect=[0,0.03,1,0.95])\n",
    "    if fake:\n",
    "        plt.suptitle('Epoch %d'%epoch)\n",
    "\n",
    "    else:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        plt.close('all')\n",
    "        #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac889595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training data\n",
    "i_plt_logs = np.random.randint(0,x_train.shape[0],16)\n",
    "plot_16_images(x_train[i_plt_logs], epoch=-1)\n",
    "plot_16_images(x_train[i_plt_logs], epoch=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c779c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training hyperparameters\n",
    "\n",
    "epochs = 350\n",
    "batch_size= 32\n",
    "save_interval=50\n",
    "\n",
    "# size of experience replay vector\n",
    "exp_size = 100\n",
    "# rate of replacement of vector\n",
    "# mean age of image ~= 1/exp_update_rate\n",
    "# max age of image ~= 250 for exp_size=100, exp_update_rate = .02\n",
    "exp_update_rate=  0.02\n",
    "num_update_exp = int(exp_size*exp_update_rate)\n",
    "exp_train = 0.2\n",
    "num_exp = int(batch_size*exp_train)\n",
    "# Adversarial ground truths\n",
    "fake = np.ones((batch_size, 1))\n",
    "valid = np.zeros((batch_size, 1))\n",
    "\n",
    "# Save random noise for plots\n",
    "noise_input = np.random.normal(0, 1, size=[16, latent_dim])\n",
    "plt_images = generator.predict(noise_input)\n",
    "plot_16_images(plt_images,epoch=0)\n",
    "\n",
    "# Save metadata and metrics\n",
    "metrics = np.empty((epochs,5))\n",
    "\n",
    "# Initialize experience replay vector\n",
    "batch_noise = np.random.normal(0,1, (exp_size,latent_dim))\n",
    "exp_images = generator.predict(batch_noise)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    # Select a random batch of images\n",
    "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "    imgs = x_train[idx]\n",
    "\n",
    "    # Sample noise and generate a batch of new images\n",
    "    batch_noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_imgs = generator.predict(batch_noise)\n",
    "\n",
    "    # Load a few old generated images\n",
    "    i_choose_exp = np.random.randint(0,exp_size,num_exp)\n",
    "    i_swap_exp = np.random.randint(0,batch_size,num_exp)\n",
    "    gen_imgs[i_swap_exp] = exp_images[i_choose_exp]\n",
    "\n",
    "    # Soft labels for discriminator\n",
    "    discriminator_fake = np.random.uniform(1.-softness,1.,(batch_size,1))\n",
    "    discriminator_valid = np.random.uniform(0.,softness,(batch_size,1))\n",
    "\n",
    "\n",
    "    # Train the discriminator (real classified as ones and generated as zeros)\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, discriminator_valid)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, discriminator_fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Generator\n",
    "    # ---------------------\n",
    "\n",
    "    # Train the generator (wants discriminator to mistake images as real)\n",
    "    g_loss = combined.train_on_batch(batch_noise, valid)\n",
    "\n",
    "    # Plot and save the progress\n",
    "    metric = (epoch, d_loss[0], 100*d_loss[1], g_loss[0], 100*g_loss[1])\n",
    "\n",
    "    metrics[epoch] = metric\n",
    "\n",
    "\n",
    "\n",
    "    # update experience replay vector\n",
    "    i_update_exp = np.random.randint(0,exp_size,num_update_exp)\n",
    "    exp_noise = np.random.normal(0,1,(num_update_exp,latent_dim))\n",
    "    exp_images[i_update_exp] = generator.predict(exp_noise)\n",
    "\n",
    "plt_images = generator.predict(noise_input)\n",
    "plot_16_images(plt_images, epoch=1+epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(metrics[:,0],metrics[:,1])\n",
    "plt.plot(metrics[:,0],metrics[:,3])\n",
    "plt.legend(['D','G'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebf1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
